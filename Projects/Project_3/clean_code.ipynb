{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BA 222 Project 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "Also mapping the variable we want to predict to a binary variable instead of yes/no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf = pd.read_csv('bankdata_training.csv').drop(['duration'], axis=1)\n",
    "\n",
    "# y comes as yes/no, but we need numbers for the linear regression\n",
    "odf['y'] = odf['y'].map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Function\n",
    "Creates dummy variables for all categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dummies(df: pd.DataFrame, target:str = 'y') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates dummy variables for categorical variables in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The input DataFrame.\n",
    "    - target (str): The target variable column name. Default is 'y'.\n",
    "\n",
    "    Returns:\n",
    "    - df (DataFrame): The modified DataFrame with dummy variables.\n",
    "\n",
    "    Example:\n",
    "    >>> df = pd.DataFrame({'Color': ['Red', 'Blue', 'Green'], 'Size': ['Small', 'Medium', 'Large']})\n",
    "    >>> df = make_dummies(df)\n",
    "    >>> print(df)\n",
    "       Color_Blue  Color_Green  Color_Red  Size_Large  Size_Medium  Size_Small\n",
    "    0           0            0          1           0            0           1\n",
    "    1           1            0          0           0            1           0\n",
    "    2           0            1          0           1            0           0\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object' and col != target:\n",
    "            df = pd.concat([df, pd.get_dummies(df[col], prefix=col, dtype=int)], axis=1)\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best model\n",
    "Finds the `num_cols` that would lead to the model with the highest $R$-squared.\n",
    "\n",
    "Every iteration of the loop, we add a new variable to the model and check if the $R$-squared increases. Then, we add the variable that led to the highest $R$-squared to the list of variables to keep. We keep on going until we have added `num_cols` variables to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nr.employed', 'poutcome_success', 'month_may', 'month_mar', 'cons.conf.idx']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = 5 # columns to find\n",
    "target = 'y' # target variable\n",
    "best_cols = [] # list of best columns\n",
    "\n",
    "odf_dummies = make_dummies(odf) # create dummy variables\n",
    "\n",
    "# Get the list of remaining columns to consider\n",
    "remaining_cols = odf_dummies.drop(target, axis=1).columns.to_list()\n",
    "\n",
    "# Filter out any columns with 'object' data type\n",
    "remaining_cols = [col for col in remaining_cols if odf_dummies[col].dtype != 'object']\n",
    "\n",
    "# Iterate until the desired number of columns is reached\n",
    "while len(best_cols) < num_cols:\n",
    "    \n",
    "    # Create a DataFrame to store the R-squared values for each column\n",
    "    testing_cols = pd.DataFrame(columns=['rsquared'])\n",
    "    \n",
    "    # Iterate over the remaining columns and calculate the R-squared value\n",
    "    for col in remaining_cols:\n",
    "        cols = best_cols + [col]\n",
    "        rsquared = sm.OLS(odf_dummies[target], sm.add_constant(odf_dummies[cols])).fit().rsquared\n",
    "        testing_cols.loc[col] = [rsquared]\n",
    "    \n",
    "    # Select the column with the highest R-squared value and remove it from the remaining columns\n",
    "    best = testing_cols.idxmax()[0]\n",
    "    best_cols.append(best)\n",
    "    remaining_cols.remove(best)\n",
    "    \n",
    "best_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model\n",
    "Using the variables we found in the previous step, we create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.199</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.198</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   204.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 01 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>1.94e-195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:38:41</td>     <th>  Log-Likelihood:    </th> <td> -592.62</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4119</td>      <th>  AIC:               </th> <td>   1197.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4113</td>      <th>  BIC:               </th> <td>   1235.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td>    6.7578</td> <td>    0.351</td> <td>   19.256</td> <td> 0.000</td> <td>    6.070</td> <td>    7.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nr.employed</th>      <td>   -0.0012</td> <td> 6.62e-05</td> <td>  -18.828</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>poutcome_success</th> <td>    0.3393</td> <td>    0.026</td> <td>   13.028</td> <td> 0.000</td> <td>    0.288</td> <td>    0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month_may</th>        <td>   -0.0855</td> <td>    0.010</td> <td>   -8.973</td> <td> 0.000</td> <td>   -0.104</td> <td>   -0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month_mar</th>        <td>    0.2688</td> <td>    0.041</td> <td>    6.487</td> <td> 0.000</td> <td>    0.188</td> <td>    0.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cons.conf.idx</th>    <td>    0.0047</td> <td>    0.001</td> <td>    4.888</td> <td> 0.000</td> <td>    0.003</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1762.071</td> <th>  Durbin-Watson:     </th> <td>   1.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>7285.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.127</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 7.935</td>  <th>  Cond. No.          </th> <td>4.16e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.16e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.199   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.198   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     204.7   \\\\\n",
       "\\textbf{Date:}             & Fri, 01 Dec 2023 & \\textbf{  Prob (F-statistic):} & 1.94e-195   \\\\\n",
       "\\textbf{Time:}             &     10:38:41     & \\textbf{  Log-Likelihood:    } &   -592.62   \\\\\n",
       "\\textbf{No. Observations:} &        4119      & \\textbf{  AIC:               } &     1197.   \\\\\n",
       "\\textbf{Df Residuals:}     &        4113      & \\textbf{  BIC:               } &     1235.   \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                           & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}             &       6.7578  &        0.351     &    19.256  &         0.000        &        6.070    &        7.446     \\\\\n",
       "\\textbf{nr.employed}       &      -0.0012  &     6.62e-05     &   -18.828  &         0.000        &       -0.001    &       -0.001     \\\\\n",
       "\\textbf{poutcome\\_success} &       0.3393  &        0.026     &    13.028  &         0.000        &        0.288    &        0.390     \\\\\n",
       "\\textbf{month\\_may}        &      -0.0855  &        0.010     &    -8.973  &         0.000        &       -0.104    &       -0.067     \\\\\n",
       "\\textbf{month\\_mar}        &       0.2688  &        0.041     &     6.487  &         0.000        &        0.188    &        0.350     \\\\\n",
       "\\textbf{cons.conf.idx}     &       0.0047  &        0.001     &     4.888  &         0.000        &        0.003    &        0.007     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 1762.071 & \\textbf{  Durbin-Watson:     } &    1.935  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 7285.030  \\\\\n",
       "\\textbf{Skew:}          &   2.127  & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &   7.935  & \\textbf{  Cond. No.          } & 4.16e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 4.16e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.199\n",
       "Model:                            OLS   Adj. R-squared:                  0.198\n",
       "Method:                 Least Squares   F-statistic:                     204.7\n",
       "Date:                Fri, 01 Dec 2023   Prob (F-statistic):          1.94e-195\n",
       "Time:                        10:38:41   Log-Likelihood:                -592.62\n",
       "No. Observations:                4119   AIC:                             1197.\n",
       "Df Residuals:                    4113   BIC:                             1235.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const                6.7578      0.351     19.256      0.000       6.070       7.446\n",
       "nr.employed         -0.0012   6.62e-05    -18.828      0.000      -0.001      -0.001\n",
       "poutcome_success     0.3393      0.026     13.028      0.000       0.288       0.390\n",
       "month_may           -0.0855      0.010     -8.973      0.000      -0.104      -0.067\n",
       "month_mar            0.2688      0.041      6.487      0.000       0.188       0.350\n",
       "cons.conf.idx        0.0047      0.001      4.888      0.000       0.003       0.007\n",
       "==============================================================================\n",
       "Omnibus:                     1762.071   Durbin-Watson:                   1.935\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7285.030\n",
       "Skew:                           2.127   Prob(JB):                         0.00\n",
       "Kurtosis:                       7.935   Cond. No.                     4.16e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.16e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sm.add_constant(odf_dummies[best_cols])\n",
    "Y = odf_dummies['y']\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the values\n",
    "Here we read the full csv and predict the values using the model we created earlier. The resulting DataFrame shows the model's performance on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_hat</th>\n",
       "      <td>0.196678</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              y     y_hat\n",
       "y      1.000000  0.196678\n",
       "y_hat  0.196678  1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the test set, drop the duration column, and convert the target variable to numbers\n",
    "test = pd.read_csv('bankdata_full.csv').drop(['duration'], axis=1)\n",
    "test['y'] = test['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results['y'] = test['y']\n",
    "\n",
    "# Create dummy variables for the test set, select the best cols, add constants, then predict with our model\n",
    "results['y_hat'] = model.predict(sm.add_constant(make_dummies(test)[best_cols]))\n",
    "results.corr()**2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
